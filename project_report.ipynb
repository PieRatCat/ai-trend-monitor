{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9557e6f8",
   "metadata": {},
   "source": [
    "# AI Trend Monitor - Project Report\n",
    "\n",
    "**Project**: AI Trend Monitor  \n",
    "**Author**: Amanda Sumner  \n",
    "**Date**: October 2025  \n",
    "**School**: EC Utbildning, DS24\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This report documents the development of an AI-powered news monitoring system as a proof-of-concept for enterprise-scale trend monitoring applications. The project demonstrates a complete pipeline for automated news collection, natural language processing, knowledge base indexing, and interactive visualization using Microsoft Azure cloud services and Python-based tools.\n",
    "\n",
    "The system was implemented through six phases: multi-source data pipeline with deduplication, Azure AI Language integration for sentiment analysis and entity recognition, Azure AI Search knowledge base indexing, responsive web dashboard with Streamlit, Retrieval-Augmented Generation (RAG) chatbot powered by GitHub Models, and automated weekly newsletter system with Azure Functions. The final system indexes 500+ curated articles from 7 active sources, provides real-time search capabilities, and delivers conversational AI queries with temporal awareness.\n",
    "\n",
    "A primary objective of this project was to evaluate AI-assisted development workflows using GitHub Copilot with Claude Sonnet 4.5. AI assistance proved highly effective for code generation, debugging, and rapid implementation, achieving an estimated 80% reduction in development time compared to traditional methods (1 month actual vs. 5+ months estimated). The project successfully validates both the technical architecture for trend monitoring systems and the practical viability of AI-assisted development for complex cloud applications.\n",
    "\n",
    "Key technical achievements include 30-40% cost optimization through early deduplication and compact storage, professional responsive design supporting multiple device sizes, and intelligent token budget management preventing API errors. The system demonstrates cost-effective cloud architecture mixing free and paid Azure tiers (under 200 SEK/month operating costs).\n",
    "\n",
    "---\n",
    "\n",
    "Denna rapport beskriver ett proof-of-concept (PoC) för ett AI-drivet nyhetsbevakningssystem för trendanalys, byggt med Microsoft Azure och Python. Systemet automatiserar datainsamling, NLP (sentiment, entiteter), indexering i Azure AI Search och inkluderar en RAG-chatbot (GitHub Models) samt en Streamlit-dashboard. Ett huvudfokus var utvärderingen av AI-assisterad utveckling (GitHub Copilot), vilket reducerade utvecklingstiden med uppskattningsvis 80% (till 1 månad). Projektet validerar den tekniska arkitekturen och demonstrerar en kostnadseffektiv drift (under 200 SEK/månad) genom optimeringar som tidig deduplicering.\n",
    "\n",
    "**Keywords**: Natural Language Processing, Azure AI Services, Web Scraping, Sentiment Analysis, RAG Architecture, AI-Assisted Development, GitHub Copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a75d96",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#1-introduction)\n",
    "2. [Theory and Background](#2-theory-and-background)\n",
    "3. [Methods](#3-methods)\n",
    "4. [Results](#4-results)\n",
    "5. [Discussion](#5-discussion)\n",
    "6. [Conclusion](#6-conclusion)\n",
    "7. [References](#7-references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a41f7",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Background and Motivation\n",
    "\n",
    "This project originated from a professional need to develop trend monitoring capabilities for enterprise applications. Organizations increasingly require automated systems to track developments in their domains, whether technology trends, market movements, regulatory changes, or competitive intelligence. Building such systems at scale demands proven architectures, cost-effective infrastructure, and reliable processing pipelines.\n",
    "\n",
    "Rather than attempting to build an enterprise system directly, this project serves as a **proof-of-concept** to validate technical approaches, evaluate cloud services, and identify potential challenges in a controlled environment. The choice of AI news as the monitoring domain was strategic: AI developments are highly relevant to both my professional work and academic studies, the topic generates sufficient article volume to test pipeline performance, and the resulting system provides practical value as a personal news aggregation tool.\n",
    "\n",
    "A second, equally important objective was to **evaluate AI-assisted development** as a methodology for complex software projects. Using GitHub Copilot throughout the development process, this project tests whether AI code generation can materially accelerate development, improve code quality, and reduce the cognitive burden of working with unfamiliar technologies and APIs.\n",
    "\n",
    "### 1.2 Project Objectives\n",
    "\n",
    "**Primary Objective**: Develop and validate a proof-of-concept architecture for enterprise-scale trend monitoring systems\n",
    "\n",
    "**Secondary Objectives**:\n",
    "1. **Pipeline Architecture**: Design robust data ingestion from multiple sources with deduplication, validation, and error handling\n",
    "2. **Cloud Integration**: Implement production-quality integration with Azure services (Storage, AI Language, AI Search, Functions)\n",
    "3. **NLP Analysis**: Apply sentiment analysis, named entity recognition, and key phrase extraction to extract insights from unstructured text\n",
    "4. **Knowledge Management**: Build searchable, indexed knowledge base enabling efficient retrieval and analysis\n",
    "5. **User Interface**: Create interactive dashboard demonstrating visualization and exploration of trend data\n",
    "6. **Chatbot Interaction**: Implement RAG-based conversational interface for natural language queries\n",
    "7. **Automation**: Deploy scheduled report generation and distribution system\n",
    "8. **AI-Assisted Development**: Document effectiveness of AI code generation throughout the project lifecycle\n",
    "\n",
    "### 1.3 Why AI News Monitoring?\n",
    "\n",
    "**Domain Relevance**:\n",
    "- AI developments directly relevant to data science studies\n",
    "- Industry knowledge essential for career development in AI/ML roles\n",
    "- Rapidly evolving field provides sufficient content volume for testing\n",
    "\n",
    "**Personal Utility**:\n",
    "- Serves as personalized news aggregator for staying current with AI trends\n",
    "- Curated content reduces time spent scanning multiple news sources\n",
    "- Conversational chatbot enables quick queries about recent developments\n",
    "\n",
    "**Technical Appropriateness**:\n",
    "- English-language content simplifies NLP processing\n",
    "- Well-defined entity types (companies, products, researchers, technologies)\n",
    "- Clear sentiment dimensions (positive/negative coverage of AI developments)\n",
    "- Sufficient article volume without overwhelming scale (150-200 articles/month)\n",
    "\n",
    "**Proof-of-Concept Validity**:\n",
    "- Techniques demonstrated here transfer directly to other domains:\n",
    "  - **Competitor monitoring**: Track mentions of competitor products, pricing, features\n",
    "  - **Regulatory tracking**: Monitor policy changes, compliance requirements, legal developments\n",
    "  - **Market intelligence**: Analyze customer sentiment, emerging needs, industry shifts\n",
    "  - **Research monitoring**: Track academic publications, clinical trials, patents\n",
    "- Architecture scales to higher volumes with minimal modifications\n",
    "- Azure services used here (Storage, AI Language, Search, Functions) are enterprise-standard\n",
    "\n",
    "### 1.4 AI-Assisted Development Approach\n",
    "\n",
    "**Development Environment**:\n",
    "- **IDE**: Visual Studio Code with GitHub Copilot extension\n",
    "- **AI Coding Assistant**: Claude Sonnet 4.5 (GitHub Copilot agent) for most of the project\n",
    "  - Initially attempted Gemini 2.5 Pro, but it proved insufficient for code generation\n",
    "  - Claude Sonnet 4.5 provided significantly higher quality responses, especially for complex code\n",
    "- **AI Assistance**: Code generation, debugging suggestions, API integration guidance\n",
    "- **Version Control**: Git with comprehensive commit history documenting AI-assisted changes\n",
    "- **Documentation**: 38 development sessions documented showing evolution and decisions\n",
    "\n",
    "**GitHub Copilot Usage Patterns**:\n",
    "1. **Boilerplate Generation**: Azure SDK integration code, configuration file structures\n",
    "2. **API Exploration**: Discovering Azure AI Language and Search API patterns\n",
    "3. **Error Handling**: Generating retry logic, validation checks, graceful degradation\n",
    "4. **Data Transformations**: Converting between article formats, cleaning HTML content\n",
    "5. **UI Components**: Streamlit dashboard layouts, chart configurations, responsive CSS\n",
    "6. **Debugging**: Identifying issues with Collection fields, date parsing, token limits\n",
    "\n",
    "**Observed Benefits** (documented throughout development sessions):\n",
    "- Significantly faster initial implementation of Azure integrations\n",
    "- Reduced context-switching when working with multiple APIs simultaneously\n",
    "- Quick generation of test utilities and debugging scripts\n",
    "- Consistent error handling patterns across modules\n",
    "- Less time spent reading documentation for syntax and method signatures\n",
    "\n",
    "**Limitations Encountered**:\n",
    "- AI suggestions sometimes outdated for rapidly evolving APIs\n",
    "- Required human judgment for architecture decisions\n",
    "- Generated code occasionally needed refactoring for clarity\n",
    "- Domain-specific optimizations (early deduplication, token budgets) required human insight\n",
    "\n",
    "**Development Time Estimation**:\n",
    "Based on traditional development experience and documented session notes, AI assistance reduced development time by approximately **80%** compared to manual coding. The project was completed in approximately 1 month (September 29 - October 29, 2025). Without AI assistance, completing a system of this complexity, learning multiple Azure services, implementing web scraping, NLP analysis, responsive design, RAG architecture, and automated newsletters, would have required an estimated 4-5 months given the need for extensive documentation reading, trial-and-error debugging, and manual boilerplate coding.\n",
    "\n",
    "### 1.5 Scope and Deliverables\n",
    "\n",
    "**In Scope**:\n",
    "- Proof-of-concept data pipeline with 7 active RSS/API sources\n",
    "- Azure cloud infrastructure demonstration (Blob Storage, AI Language, AI Search, Functions)\n",
    "- Interactive web dashboard (Streamlit) with 5 pages: News, Analytics, Chatbot, Subscribe, About\n",
    "- RAG chatbot with temporal query detection and token management\n",
    "- Automated weekly newsletter generation and delivery\n",
    "- Responsive design supporting desktop, tablet, and mobile devices\n",
    "- Comprehensive documentation of architecture, decisions, and AI-assisted development\n",
    "\n",
    "**Out of Scope**:\n",
    "- Enterprise-scale deployment (multi-tenant, load balancing, high availability)\n",
    "- Real-time social media monitoring (Twitter/X API costs prohibitive for proof-of-concept)\n",
    "- Video/podcast transcription and analysis (high processing costs)\n",
    "- Custom machine learning model training (pre-trained Azure AI models sufficient)\n",
    "- Multi-language support (English-only simplifies proof-of-concept)\n",
    "- User authentication and role-based access (not needed for personal use)\n",
    "- Production-grade monitoring and alerting (basic Azure monitoring sufficient)\n",
    "\n",
    "**Deliverables**:\n",
    "1. **Functional Pipeline**: `run_pipeline.py` (8-stage processing), `run_weekly_pipeline.py` (report generation)\n",
    "2. **Cloud Infrastructure**: Configured Azure resources (Storage, AI Language, AI Search, Functions, Communication Services)\n",
    "3. **Web Dashboard**: `streamlit_app/app.py`, responsive CSS, 4 functional pages\n",
    "4. **Documentation**: \n",
    "   - Project report (this document - comprehensive technical documentation)   \n",
    "   - GitHub repository with complete source code and commit history\n",
    "5. **Deployed Systems**: \n",
    "   - Live web dashboard running on Azure Web App: https://trends.goblinsen.se (personal domain)\n",
    "   - Automated newsletter system running on Azure Functions (Fridays 9 AM UTC)\n",
    "\n",
    "### 1.6 Technical Context\n",
    "\n",
    "**Development Environment**:\n",
    "- **Language**: Python 3.12.11\n",
    "- **Environment Manager**: Conda (`trend-monitor` environment)\n",
    "- **IDE**: Visual Studio Code 1.85+ with GitHub Copilot\n",
    "- **Version Control**: Git + GitHub (repository: `ai-trend-monitor`)\n",
    "- **Operating System**: Windows 11 (development), Linux (Azure Functions runtime)\n",
    "\n",
    "**Target Users** (for enterprise trend monitoring systems):\n",
    "- **Corporate Strategy Teams**: Tracking competitive intelligence, market trends\n",
    "- **Product Managers**: Monitoring customer sentiment, feature requests, competitor moves\n",
    "- **Compliance Officers**: Following regulatory changes, policy developments\n",
    "- **Research Teams**: Aggregating academic publications, clinical trials, patents\n",
    "- **Marketing Teams**: Analyzing brand sentiment, campaign effectiveness, industry buzz\n",
    "\n",
    "**Personal Use** (for this implementation):\n",
    "- Author as primary user for AI news consumption\n",
    "- Newsletter subscribers (opt-in via dashboard)\n",
    "- Portfolio demonstration for potential employers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9632b876",
   "metadata": {},
   "source": [
    "## 2. Theory and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a50e8",
   "metadata": {},
   "source": [
    "### 2.1 Natural Language Processing (NLP)\n",
    "\n",
    "Natural Language Processing enables computers to understand, interpret, and generate human language. This project leverages three core NLP techniques:\n",
    "\n",
    "**Sentiment Analysis**: Computational identification of subjective opinions expressed in text, classifying sentiment as positive, negative, neutral, or mixed with confidence scores. Sentiment analysis helps track public perception of AI developments over time.\n",
    "\n",
    "**Named Entity Recognition (NER)**: Automated extraction of entities (organizations, people, locations, technologies) from unstructured text. NER enables identification of key players in the AI landscape (companies like OpenAI, researchers, technologies like GPT-4).\n",
    "\n",
    "**Key Phrase Extraction**: Statistical and linguistic methods to identify salient terms and concepts within documents. Key phrases reveal trending topics and enable topic clustering for analytics.\n",
    "\n",
    "**Azure AI Language Service**: Microsoft's cloud-based NLP platform providing pre-trained models for sentiment analysis, NER, and key phrase extraction. Chosen for cost-effectiveness, batch processing capabilities, and integration with other Azure services.\n",
    "\n",
    "### 2.2 Information Retrieval and Search\n",
    "\n",
    "**Keyword Search**: Traditional text-matching algorithms using inverted indexes to find documents containing query terms. Fast and precise but limited to exact matches and synonyms.\n",
    "\n",
    "**Semantic Search**: Advanced retrieval using vector embeddings and neural networks to understand query intent and document meaning beyond keywords. Captures conceptual similarity between queries and documents.\n",
    "\n",
    "**Azure AI Search**: Microsoft's cloud search service supporting both keyword and semantic search (on paid tiers). Provides faceted navigation, filtering, and full-text search capabilities with scalable indexing.\n",
    "\n",
    "**Search Index Schema**: Structured definition of searchable fields, data types, and attributes. This project uses 14 fields including title, content, sentiment scores, entities, and metadata with appropriate configurations for searchability and filtering.\n",
    "\n",
    "### 2.3 Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "RAG combines information retrieval with large language model (LLM) generation to produce grounded, factual responses. The architecture consists of:\n",
    "\n",
    "1. **Query Processing**: User question analyzed to extract intent and temporal constraints\n",
    "2. **Retrieval**: Relevant documents fetched from knowledge base using search\n",
    "3. **Context Formatting**: Retrieved documents formatted into structured prompt\n",
    "4. **Generation**: LLM synthesizes answer using retrieved context as evidence\n",
    "5. **Citation**: Response includes references to source documents\n",
    "\n",
    "**Benefits over Pure LLM**:\n",
    "- Grounded in actual data (reduces hallucinations)\n",
    "- Citable sources (transparency and verification)\n",
    "- Up-to-date information (knowledge base continuously updated)\n",
    "- Domain-specific (tailored to AI news corpus)\n",
    "\n",
    "**GitHub Models**: Free-tier LLM hosting platform providing access to OpenAI's GPT-4.1-mini for development and testing before production migration to Azure AI Foundry.\n",
    "\n",
    "### 2.4 Web Development Technologies\n",
    "\n",
    "**Streamlit**: Python-based web framework for rapid development of data applications. Chosen for:\n",
    "- Native Python integration (no JavaScript required)\n",
    "- Built-in components for charts, tables, forms\n",
    "- Reactive programming model (automatic UI updates)\n",
    "- Quick prototyping and iteration\n",
    "\n",
    "**Responsive Web Design**: Design approach ensuring usability across device sizes using:\n",
    "- **Fluid Grids**: Percentage-based layouts that adapt to viewport width\n",
    "- **Flexible Images**: CSS scaling to prevent overflow\n",
    "- **Media Queries**: CSS rules targeting specific screen sizes (breakpoints)\n",
    "- **Viewport Meta Tag**: Proper mobile device rendering\n",
    "\n",
    "\n",
    "### 2.5 Cloud Architecture Patterns\n",
    "\n",
    "**Serverless Computing**: Cloud execution model where provider manages infrastructure. Azure Functions used for:\n",
    "- Timer-triggered pipeline execution (weekly newsletter)\n",
    "- HTTP-triggered API endpoints (subscription management)\n",
    "- Automatic scaling and cost efficiency (pay-per-execution)\n",
    "\n",
    "**Blob Storage**: Object storage for unstructured data. Used for:\n",
    "- Raw article content (cleaned HTML)\n",
    "- Analyzed articles (with NLP insights)\n",
    "- URL registry (deduplication tracking)\n",
    "- Newsletter subscriber data (Azure Table Storage)\n",
    "\n",
    "**Tiered Service Strategy**: Mixing free and paid Azure tiers based on actual needs:\n",
    "- Free tier where sufficient (AI Search: 50MB, 10K docs)\n",
    "- Standard tier where necessary (AI Language: >5K calls/month)\n",
    "- Cost optimization through early filtering and compact storage\n",
    "\n",
    "### 2.6 Data Pipeline Design\n",
    "\n",
    "**ETL (Extract, Transform, Load)**: Traditional data integration pattern adapted for news monitoring:\n",
    "\n",
    "**Extract**: Fetch articles from APIs and RSS feeds\n",
    "- Guardian API with date filtering (`from-date` parameter)\n",
    "- RSS feeds parsed with `feedparser` library\n",
    "- Web scraping for full article content\n",
    "\n",
    "**Transform**: Clean, deduplicate, and analyze content\n",
    "- HTML entity decoding and Unicode normalization\n",
    "- URL deduplication using Set-based registry\n",
    "- Azure AI Language batch processing (25 docs at once)\n",
    "- Content filtering (minimum 100 characters)\n",
    "\n",
    "**Load**: Store results in multiple destinations\n",
    "- Azure Blob Storage (persistent files)\n",
    "- Azure AI Search index (searchable knowledge base)\n",
    "- URL registry update (prevent reprocessing)\n",
    "\n",
    "**Pipeline Orchestration**: Sequential execution with error handling and logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe92b95",
   "metadata": {},
   "source": [
    "## 3. Methods\n",
    "\n",
    "### 3.1 System Architecture Overview\n",
    "\n",
    "The AI Trend Monitor implements a cloud-based, microservices-inspired architecture with three main layers:\n",
    "\n",
    "**Data Ingestion Layer**:\n",
    "- Guardian API client (`src/api_fetcher.py`)\n",
    "- RSS feed parser (`src/rss_fetcher.py`)\n",
    "- Web scraper with site-specific selectors (`src/scrapers.py`)\n",
    "- Date filtering at source (June 1, 2025 onwards)\n",
    "\n",
    "**Processing Layer**:\n",
    "- HTML cleaning and text extraction (`src/data_cleaner.py`)\n",
    "- Azure AI Language integration (`src/language_analyzer.py`)\n",
    "- Batched NLP analysis (25 documents per request)\n",
    "- Content validation and truncation handling\n",
    "\n",
    "**Storage and Retrieval Layer**:\n",
    "- Azure Blob Storage operations (`src/storage.py`)\n",
    "- Azure AI Search indexing (`src/search_indexer.py`)\n",
    "- URL registry for deduplication (`processed_urls.json`)\n",
    "- Compact JSON serialization (no indentation)\n",
    "\n",
    "**Presentation Layer**:\n",
    "- Streamlit web application (`streamlit_app/app.py`)\n",
    "- RAG chatbot (`src/rag_chatbot.py`)\n",
    "- External CSS styling (`streamlit_app/styles.css`)\n",
    "\n",
    "**Automation Layer**:\n",
    "- Azure Functions timer trigger (weekly pipeline)\n",
    "- GPT-4.1-mini report generation (`src/generate_weekly_report.py`)\n",
    "- Azure Communication Services email delivery\n",
    "- Double opt-in subscription system (`src/subscriber_manager.py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b672ee9",
   "metadata": {},
   "source": [
    "### 3.2 Data Collection Methodology\n",
    "\n",
    "**Source Selection Criteria**:\n",
    "1. AI-focused content (primary topic, not incidental mentions)\n",
    "2. Regular publication frequency (minimum weekly)\n",
    "3. Professional editorial standards\n",
    "4. RSS feed or API availability\n",
    "5. English language content\n",
    "\n",
    "**Active RSS Feeds** (7 sources as of October 23, 2025):\n",
    "- **The Guardian API**: Major news publication with AI category filtering\n",
    "- **TechCrunch**: Technology news with AI-specific RSS feeds\n",
    "- **VentureBeat**: AI industry coverage and trends\n",
    "- **Ars Technica**: Technical analysis and research focus\n",
    "- **Gizmodo**: Consumer technology and AI applications\n",
    "- **IEEE Spectrum**: Academic research and engineering\n",
    "- **The Register UK**: Critical technology journalism\n",
    "- **The Verge**: Product launches and reviews\n",
    "\n",
    "**Removed Sources** (historical articles remain indexed):\n",
    "- **EU-Startups** (Removed Oct 23, 2025): Azure cloud IP blocking (403 Forbidden errors). Enhanced headers did not resolve the issue. Historical articles from this source remain in the search index for analytics but no new articles are fetched.\n",
    "\n",
    "**Note**: The Analytics page source list shows all sources with indexed articles, including discontinued sources. This distinction between \"active RSS feeds\" (currently fetching) and \"indexed sources\" (have historical data) is intentional for comprehensive trend analysis.\n",
    "\n",
    "**Data Collection Process**:\n",
    "\n",
    "1. **API Fetching** (Guardian):\n",
    "   ```python\n",
    "   params = {\n",
    "       'api-key': api_key,\n",
    "       'q': query_string,\n",
    "       'from-date': '2025-06-01',  # Filter at source\n",
    "       'page-size': 50\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **RSS Parsing** (8 feeds):\n",
    "   - Use `feedparser` library for XML parsing\n",
    "   - Extract: title, link, published date, description\n",
    "   - Standardize date formats with `dateutil.parser`\n",
    "\n",
    "3. **Web Scraping** (full article content):\n",
    "   - Site-specific CSS selectors (e.g., `div.article-body` for VentureBeat)\n",
    "   - Fallback selector list for unknown sites\n",
    "   - Exponential backoff for rate limiting (1, 2, 4, 8 seconds)\n",
    "   - 5MB HTML size limit to prevent parsing hangs\n",
    "\n",
    "4. **Deduplication**:\n",
    "   - Check URLs against registry BEFORE scraping\n",
    "   - Uses Python set data structure for instant lookup\n",
    "   - Store registry in `analyzed-articles` container\n",
    "\n",
    "**Quality Assurance Measures**:\n",
    "- Content length validation (minimum 100 characters)\n",
    "- HTML entity decoding and Unicode normalization\n",
    "- Truncation warnings for articles >5120 characters\n",
    "- Graceful error handling (empty list returns on failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5e2c5",
   "metadata": {},
   "source": [
    "### 3.3 Natural Language Processing Implementation\n",
    "\n",
    "**Azure AI Language Service Configuration**:\n",
    "- Tier: Standard (S) - Pay-per-transaction\n",
    "- Region: Sweden Central\n",
    "- Batch size: 25 documents per request\n",
    "- Character limit: 5120 per document\n",
    "\n",
    "**Analysis Pipeline**:\n",
    "\n",
    "1. **Sentiment Analysis**:\n",
    "   - Overall document sentiment (Positive/Negative/Neutral/Mixed)\n",
    "   - Confidence scores for each sentiment category\n",
    "   - Net sentiment calculation: `positive_score - negative_score`\n",
    "\n",
    "2. **Named Entity Recognition**:\n",
    "   - Categories: Organization, Person, Location, Product, Technology\n",
    "   - Frequency counting for trend analysis\n",
    "   - Entity disambiguation (case-insensitive matching)\n",
    "\n",
    "3. **Key Phrase Extraction**:\n",
    "   - Statistical relevance scoring\n",
    "   - Multi-word phrase detection\n",
    "   - Deduplication and normalization\n",
    "\n",
    "**Batch Processing Logic**:\n",
    "```python\n",
    "def analyze_content_batch(articles, language_key, language_endpoint):\n",
    "    batch_size = 25\n",
    "    for i in range(0, len(articles), batch_size):\n",
    "        batch = articles[i:i+batch_size]\n",
    "        documents = [\n",
    "            {\n",
    "                'id': str(idx),\n",
    "                'text': article['content'][:5120],  # Truncate\n",
    "                'language': 'en'\n",
    "            }\n",
    "            for idx, article in enumerate(batch)\n",
    "        ]\n",
    "        # Call Azure AI Language API\n",
    "        # Parse and merge results\n",
    "```\n",
    "\n",
    "**Error Handling**:\n",
    "- Timeout handling for long-running batches\n",
    "- Partial result returns (skip failed documents)\n",
    "- Extensive logging for debugging\n",
    "- Retry logic with exponential backoff\n",
    "\n",
    "### 3.4 Knowledge Base Indexing\n",
    "\n",
    "**Azure AI Search Index Schema** (14 fields):\n",
    "\n",
    "**Core Content Fields**:\n",
    "- `id`: Unique document identifier (MD5 hash of URL)\n",
    "- `title`: Article headline (searchable, sortable)\n",
    "- `content`: Full article text (searchable, up to 5120 chars)\n",
    "- `link`: Article URL (filterable, not searchable)\n",
    "- `source`: Publication name (filterable, facetable)\n",
    "- `published_date`: Original publication timestamp (sortable, filterable)\n",
    "\n",
    "**NLP Analysis Fields**:\n",
    "- `sentiment_overall`: Overall sentiment label (filterable, facetable)\n",
    "- `sentiment_positive`: Positive confidence score (sortable)\n",
    "- `sentiment_negative`: Negative confidence score (sortable)\n",
    "- `key_phrases`: Collection of extracted phrases (searchable, limited to 100)\n",
    "- `entities`: Collection of entity names (searchable, limited to 50)\n",
    "- `entity_categories`: Collection of entity types (filterable, facetable)\n",
    "\n",
    "**Metadata Fields**:\n",
    "- `indexed_at`: Indexing timestamp (sortable)\n",
    "- `net_sentiment`: Calculated field (positive - negative scores)\n",
    "\n",
    "**Index Configuration**:\n",
    "- Tier: Free (F) - 0 SEK/month\n",
    "- Capacity: 50 MB storage, 10,000 documents max\n",
    "- Search type: Keyword (semantic requires paid tier)\n",
    "- Current usage: 588 documents indexed (October 28, 2025)\n",
    "\n",
    "**Indexing Process**:\n",
    "```python\n",
    "def transform_article_for_search(article):\n",
    "    return {\n",
    "        'id': hashlib.md5(article['link'].encode()).hexdigest(),\n",
    "        'title': article['title'],\n",
    "        'content': article['content'][:5120],\n",
    "        'link': article['link'],\n",
    "        'source': article['source'],\n",
    "        'published_date': article['published_date'],\n",
    "        'sentiment_overall': article['sentiment']['overall'],\n",
    "        'sentiment_positive': article['sentiment']['positive'],\n",
    "        'sentiment_negative': article['sentiment']['negative'],\n",
    "        'key_phrases': article['key_phrases'][:100],  # Limit\n",
    "        'entities': [e['name'] for e in article['entities']][:50],\n",
    "        'entity_categories': list(set([e['category'] for e in article['entities']])),\n",
    "        'indexed_at': datetime.utcnow().isoformat() + 'Z',\n",
    "        'net_sentiment': article['sentiment']['positive'] - article['sentiment']['negative']\n",
    "    }\n",
    "```\n",
    "\n",
    "**Merge Strategy**: Using `merge_or_upload_documents()` for graceful duplicate handling.\n",
    "\n",
    "### 3.5 Dashboard Development\n",
    "\n",
    "**Technology Stack**:\n",
    "- Framework: Streamlit 1.50.0\n",
    "- Visualization: Matplotlib, Plotly\n",
    "- Layout: Custom CSS with responsive breakpoints\n",
    "- Deployment: Azure Web App Service\n",
    "\n",
    "**Page Structure**:\n",
    "\n",
    "**1. News Page**:\n",
    "- **Search Articles**\n",
    "  - Keyword search with source and date range filters\n",
    "  - Search results displayed as article cards\n",
    "  - Each card shows: title, source, date, sentiment badge, content preview, key phrases\n",
    "  - Click-through links to original articles\n",
    "- **AI News & Updates**\n",
    "  - GPT-generated summaries of recent developments\n",
    "  - Two sections: \"Products & Industry News\" and \"Research & Development\"\n",
    "  - Generated weekly, cached in Azure Blob Storage\n",
    "  - Static fallback content if generation fails\n",
    "\n",
    "**2. Analytics Page**\n",
    "- **Topic Trend Timeline**\n",
    "  - Entity selection dropdown + text search\n",
    "  - Dual-axis chart: Article count (left axis) + Net sentiment (right axis)\n",
    "  - Three visualization modes: Daily Count, Cumulative Count, Weekly Aggregation\n",
    "  - 4 metrics below chart: Total Articles, Positive %, Negative %, Date Range\n",
    "\n",
    "- **Net Sentiment Distribution**\n",
    "  - Histogram with KDE overlay showing sentiment spectrum (-1 to +1)\n",
    "  - 8 sentiment metrics: Positive, Neutral, Negative, Mixed, Leaning Positive, Leaning Negative, Mean Score, Median Score\n",
    "  \n",
    "\n",
    "- **Source Statistics & Growth**\n",
    "  - **Sentiment Distribution by Source**: HTML table showing each source with:\n",
    "    - Source name\n",
    "    - Article count\n",
    "    - Horizontal stacked bar chart (Negative → Neutral → Positive → Mixed)\n",
    "    - Bar percentages displayed for each sentiment category\n",
    "    - Ordered by article count (descending)\n",
    "  - **Growth Overview** section:\n",
    "    - Total Articles\n",
    "    - Latest Month stats with growth indicators (percentage change from previous month)\n",
    "    - Date Range (earliest to latest article)\n",
    "\n",
    "- **Top Topics Analysis**\n",
    "  - Topic distribution table requiring minimum 2 sources (eliminates single-source spam)\n",
    "  - Shows: Rank, Topic, Mentions, Articles, Sources\n",
    "\n",
    "- **Word Cloud**\n",
    "  - Entity frequency visualization with custom color scheme\n",
    "  \n",
    "\n",
    "**3. Chatbot Page** (RAG Chatbot):\n",
    "- Conversational interface with message history persistence\n",
    "- Clean, minimal design focused on the chat experience\n",
    "- Temporal query detection (\"last 24 hours\", \"past week\", \"last X days\")\n",
    "- Citation-based responses with numbered references ([1], [2], [3])\n",
    "- Token budget management (5000 tokens default, 3500 with conversation history)\n",
    "- Default retrieval: 15 articles per query for comprehensive context\n",
    "- Click citations to view source article details\n",
    "- Powered by GPT-4.1-mini (GitHub Models)\n",
    "\n",
    "**4. Subscribe Page**:\n",
    "- Email input form with validation\n",
    "- Double opt-in confirmation workflow\n",
    "- GDPR-compliant consent checkbox\n",
    "- Success messaging with confirmation email notification\n",
    "- Unsubscribe link handling with confirmation\n",
    "- Error messaging for invalid inputs or failed subscriptions\n",
    "\n",
    "**5. About Page**:\n",
    "- Project overview\n",
    "- Contact details\n",
    "\n",
    "**Responsive Design Implementation**:\n",
    "\n",
    "**CSS Externalization** (`styles.css`):\n",
    "```css\n",
    "/* Viewport-based font scaling */\n",
    "h1 { font-size: clamp(1.5rem, 4vw, 2.5rem) !important; }\n",
    "h2 { font-size: clamp(1.2rem, 3vw, 1.8rem) !important; }\n",
    "p { font-size: clamp(0.9rem, 1.5vw, 1rem) !important; }\n",
    "\n",
    "/* Breakpoints */\n",
    "@media screen and (max-width: 1200px) { /* Single column */ }\n",
    "@media screen and (max-width: 1024px) { /* Tablet padding */ }\n",
    "@media screen and (max-width: 768px) { /* Mobile touch targets */ }\n",
    "@media screen and (max-width: 480px) { /* Small phone fonts */ }\n",
    "```\n",
    "\n",
    "**Chart Responsiveness**:\n",
    "- CSS-based scaling (width: 100%, height: auto)\n",
    "- Python helper: `get_responsive_figsize(base_width, base_height)`\n",
    "- Maintains aspect ratio across devices\n",
    "\n",
    "**Color Palette** (AITREND_COLOURS):\n",
    "- Professional warm beige/tan tones\n",
    "- Teal for positive sentiment (colorblind-safe)\n",
    "- Amber/orange for negative sentiment (colorblind-safe)\n",
    "- High contrast for WCAG AA compliance\n",
    "\n",
    "### 3.6 RAG Chatbot Implementation\n",
    "\n",
    "**Architecture Components**:\n",
    "\n",
    "1. **Query Processing**:\n",
    "   - Temporal query detection with regex patterns\n",
    "   - Date range extraction (\"last 24 hours\" → datetime cutoff)\n",
    "   - Query enhancement for search relevance\n",
    "\n",
    "2. **Document Retrieval**:\n",
    "   - Azure AI Search query with filters\n",
    "   - Temporal queries: `order_by=\"published_date desc\"`\n",
    "   - Default queries: relevance-based ranking\n",
    "   - Top-K retrieval (default 15 articles)\n",
    "\n",
    "3. **Context Formatting**:\n",
    "   - Token budget calculation based on article count\n",
    "   - Adaptive content truncation (chars_per_article)\n",
    "   - Structured format with numbered citations\n",
    "   - Metadata inclusion (title, source, date, URL)\n",
    "\n",
    "4. **Response Generation**:\n",
    "   - GitHub Models endpoint (GPT-4.1-mini)\n",
    "   - System prompt with grounding instructions\n",
    "   - Conversation history support\n",
    "   - Citation enforcement in responses\n",
    "\n",
    "5. **Token Management**:\n",
    "   ```python\n",
    "   # Budget allocation\n",
    "   token_budget = 5000  # Single query\n",
    "   token_budget = 3500  # With conversation history\n",
    "   \n",
    "   # Per-article content calculation\n",
    "   chars_per_token = 4\n",
    "   max_chars = token_budget * chars_per_token\n",
    "   metadata_overhead = num_articles * 200  # ~50 tokens\n",
    "   available_chars = max_chars - metadata_overhead\n",
    "   chars_per_article = max(300, available_chars // num_articles)\n",
    "   ```\n",
    "\n",
    "**Temporal Query Patterns**:\n",
    "- \"last 24 hours\", \"past 24 hours\", \"today\"\n",
    "- \"last 48 hours\", \"past 48 hours\"\n",
    "- \"last X days\", \"past X days\" (dynamic extraction)\n",
    "- \"this week\", \"last week\", \"past week\"\n",
    "- \"this month\", \"last month\", \"past month\"\n",
    "\n",
    "**Error Handling**:\n",
    "- 413 errors: Automatic token budget reduction\n",
    "- Empty result sets: Helpful fallback messages\n",
    "- API failures: Graceful degradation with error display\n",
    "- Rate limiting: Exponential backoff\n",
    "\n",
    "### 3.7 Newsletter Automation\n",
    "\n",
    "**Azure Functions Configuration**:\n",
    "- Runtime: Python 3.12\n",
    "- Trigger: Timer (Cron: `0 0 9 * * 5` - Fridays 9 AM UTC)\n",
    "- Flex Consumption plan (pay-per-execution)\n",
    "- Operating System: Linux\n",
    "- Instance Memory: 2048 MB\n",
    "- Timeout: Extended for GPT processing\n",
    "\n",
    "**Report Generation Workflow**:\n",
    "\n",
    "1. **Data Collection**:\n",
    "   - Query Azure AI Search for past 7 days\n",
    "   - Retrieve 200+ analyzed articles\n",
    "   - Filter by date range and quality metrics\n",
    "\n",
    "2. **GPT-4.1-mini Analysis** (Three-section format):\n",
    "   - **Executive Summary** (150-200 words):\n",
    "     - Narrative overview of key developments\n",
    "     - High-level trends and patterns\n",
    "   - **Models and Research** (3-4 paragraphs):\n",
    "     - LLM updates and technical breakthroughs\n",
    "     - Academic developments and research papers\n",
    "     - Model performance improvements\n",
    "   - **Tools and Platforms** (2-3 paragraphs):\n",
    "     - Developer tools, APIs, and integrations\n",
    "     - Product launches and platform updates\n",
    "     - Ecosystem developments\n",
    "\n",
    "3. **GPT-Based Entity Extraction**:\n",
    "   - GPT analyzes generated content (not database)\n",
    "   - Identifies 24+ companies, products, technologies mentioned\n",
    "   - Returns clean list without generic terms\n",
    "   - Example entities: OpenAI, ChatGPT, Anthropic, GPT-4, Microsoft 365 Copilot, TPU\n",
    "\n",
    "4. **Interactive Entity Linking**:\n",
    "   - 45+ clickable links embedded in email content\n",
    "   - Links format: `https://trends.goblinsen.se?search={entity}`\n",
    "   - Dashboard auto-detects query parameter and pre-populates search\n",
    "   - Search executes automatically when page loads\n",
    "   - Limits: 3 occurrences per entity to avoid over-linking\n",
    "\n",
    "5. **HTML Email Template**:\n",
    "   - Mobile-responsive design with inline CSS\n",
    "   - Styled entity links with hover effects\n",
    "   - Professional typography and spacing\n",
    "   - Unsubscribe link in footer\n",
    "\n",
    "6. **Distribution**:\n",
    "   - Azure Communication Services (sender: DoNotReply@goblinsen.se)\n",
    "   - BCC delivery for privacy protection\n",
    "   - Delivery status tracking\n",
    "   - Bounce handling and error logging\n",
    "\n",
    "**Subscription Management**:\n",
    "- Azure Table Storage for subscriber data\n",
    "- Double opt-in workflow (email confirmation required)\n",
    "- Confirmation email with verification link\n",
    "- Unsubscribe endpoint (HTTP trigger in Azure Functions)\n",
    "- GDPR-compliant consent tracking with checkboxes\n",
    "- Subscriber status: \"pending\" (awaiting confirmation) or \"active\" (confirmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256802a",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "\n",
    "### 4.1 System Performance Metrics\n",
    "\n",
    "**Data Collection Efficiency**:\n",
    "- Articles indexed: 588 (after quality curation)\n",
    "- Data sources: 7 active RSS feeds (9 total sources in index including historical)\n",
    "- Date range: June 3, 2025 - October 28, 2025 (5 months)\n",
    "- Pipeline execution time: ~20-30 seconds per run\n",
    "- New articles per run: 0-29 (varies by publication frequency)\n",
    "- Deduplication rate: ~99% (URL registry prevents redundant processing)\n",
    "\n",
    "**Storage Optimization**:\n",
    "- Compact JSON storage: 30-40% space reduction vs. indented format\n",
    "- URL registry: 588 unique URLs tracked\n",
    "- Blob containers: 3 (raw-articles, analyzed-articles, curated-content)\n",
    "- Typical file sizes: 8-20 KB per pipeline run\n",
    "\n",
    "**NLP Processing**:\n",
    "- Batch size: 25 documents per request\n",
    "- Average processing time: 30-60 seconds per batch\n",
    "- Content filtering: Articles <100 chars skipped (prevents wasted API calls)\n",
    "- Truncation rate: ~10% of articles exceed 5120 char limit\n",
    "\n",
    "**Search Index Statistics**:\n",
    "- Documents indexed: 588\n",
    "- Storage used: ~8 MB (of 50 MB capacity)\n",
    "- Average query latency: <100ms\n",
    "- Fields per document: 14\n",
    "- Free tier utilization: 16% storage, 5.9% document count\n",
    "\n",
    "**Dashboard Performance**:\n",
    "- Total articles: 500+ (588 indexed)\n",
    "- Search filtering: Instant client-side processing\n",
    "- Chatbot response time: 2-5 seconds (typical queries)\n",
    "- Email delivery: <2 seconds (confirmation emails)\n",
    "- Responsive breakpoints: 5 levels (1920px, 1366px, 1024px, 768px, 480px)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a04d3d",
   "metadata": {},
   "source": [
    "### 4.2 RAG Chatbot Performance\n",
    "\n",
    "**Query Response Quality**:\n",
    "- Temporal queries: 100% accurate date filtering (tested with \"last 24 hours\", \"past week\")\n",
    "- Citation accuracy: All responses include numbered source references\n",
    "- Token management: Zero 413 errors after implementation\n",
    "- Response relevance: High-quality answers grounded in retrieved articles\n",
    "\n",
    "**Token Budget Effectiveness**:\n",
    "- Single query budget: 5000 tokens → supports 15 articles at ~1133 chars/article\n",
    "- With history budget: 3500 tokens → supports 12 articles at ~950 chars/article\n",
    "- Success rate: 100% (no token limit errors in production testing)\n",
    "\n",
    "**Temporal Query Detection Examples**:\n",
    "```\n",
    "Query: \"Summarize news from the last 24 hours\"\n",
    "→ Detected: \"last 24 hours\"\n",
    "→ Cutoff: 2025-10-16 21:12:18\n",
    "→ Retrieved: 17 articles from Oct 16, 2025\n",
    "→ Response: Comprehensive summary with [1]-[17] citations\n",
    "\n",
    "Query: \"What happened in the past week?\"\n",
    "→ Detected: \"past week\"\n",
    "→ Cutoff: 2025-10-09\n",
    "→ Retrieved: 85 articles (sorted by date descending)\n",
    "→ Response: Weekly trend summary with top 15 articles cited\n",
    "```\n",
    "\n",
    "**Limited Information Handling**:\n",
    "- Enhanced prompts acknowledge partial information\n",
    "- Example: \"Wayve\" query with boilerplate mentions\n",
    "  - Before: \"No information available\"\n",
    "  - After: \"Wayve appears in conference speaker lists [1][2] and is described as a U.K. self-driving startup that received $1.05B investment [10]\"\n",
    "\n",
    "**Response Time**:\n",
    "- Average: 2-5 seconds\n",
    "- With history: 3-6 seconds\n",
    "- Factors: Article retrieval (0.1s) + Content formatting (0.1s) + LLM generation (2-5s)\n",
    "\n",
    "### 4.3 Newsletter System Performance\n",
    "\n",
    "**Automated Report Generation**:\n",
    "- Execution: Every Friday 9:00 AM UTC via Azure Functions\n",
    "- Generation time: 15-25 seconds per report\n",
    "- Token cost: ~5000 tokens/report (~$0.0035 per report)\n",
    "- Report length: 1500-2500 words\n",
    "- Report structure: 3 sections (Executive Summary, Models/Research, Tools/Platforms)\n",
    "\n",
    "**GPT Entity Extraction Results**:\n",
    "- Entities identified per report: 24+ (companies, products, technologies)\n",
    "- Interactive links embedded: 45+ clickable entity mentions\n",
    "- Entity linking accuracy: 100% (GPT extracts only mentioned entities)\n",
    "- Dashboard integration: Query parameters enable auto-search from email\n",
    "\n",
    "**Email Delivery Performance**:\n",
    "- Delivery success rate: 100% (no bounces during testing)\n",
    "- Confirmation email speed: <2 seconds\n",
    "- Template: Mobile-responsive HTML with inline CSS\n",
    "- Subscription workflow: Double opt-in with Azure Table Storage\n",
    "\n",
    "**Content Quality Metrics** (Sample from October 28, 2025):\n",
    "- Executive Summary: 150-200 words narrative overview\n",
    "- Models and Research: 3-4 paragraphs covering LLM updates and breakthroughs\n",
    "- Tools and Platforms: 2-3 paragraphs on developer tools and integrations\n",
    "- Overall tone: Professional, informative, accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2da9f",
   "metadata": {},
   "source": [
    "### 4.4 Cost Analysis\n",
    "\n",
    "**Azure Service Costs** (October 2025):\n",
    "- **Total accumulated** (Oct 1-28): 195 SEK\n",
    "- **Projected month-end total**: ~291 SEK\n",
    "- **Budget alert threshold**: 200 SEK (monitoring, not yet exceeded)\n",
    "- **Daily average**: ~7 SEK (actual usage, excluding zero-cost days)\n",
    "\n",
    "**Cost Pattern Analysis**:\n",
    "- Peak spending days: Oct 14 (65 SEK), Oct 22 (45 SEK) - major pipeline runs with NLP analysis\n",
    "- Typical daily cost: 7-15 SEK (pipeline execution days)\n",
    "- Zero-cost days: 14 of 28 days (50%) - no pipeline activity\n",
    "- Development phase impact: Higher costs during active development and testing (Oct 14-26)\n",
    "\n",
    "**Service Cost Breakdown** (Estimated from October usage):\n",
    "- **Azure AI Language**: ~140-185 SEK/month (Standard tier, NLP analysis batches)\n",
    "- **Azure Communication Services**: ~47-56 SEK/month (email delivery testing and newsletters)\n",
    "- **Azure Blob Storage**: <5 SEK/month (pay-as-you-go, ~500KB data)\n",
    "- **Azure Functions**: <9 SEK/month (Flex Consumption plan, weekly execution)\n",
    "- **Azure AI Search**: 0 SEK/month (Free tier, well within limits)\n",
    "- **GitHub Models**: 0 SEK/month (free tier for chatbot development)\n",
    "\n",
    "**Cost Optimization Strategies Implemented**:\n",
    "1. Early URL deduplication: Saves ~130 Azure AI Language API calls per run\n",
    "2. Content filtering: Skips articles <100 chars before analysis (prevents wasted API calls)\n",
    "3. Compact JSON storage: 30-40% space reduction in blob storage\n",
    "4. Free tier Azure AI Search: Sufficient for 10,000 documents (currently 588)\n",
    "5. GitHub Models for chatbot: Free LLM access during development phase\n",
    "6. Batched NLP processing: 25 documents per request reduces API overhead\n",
    "\n",
    "**Production Cost Projection** (steady-state operation):\n",
    "- **Pipeline automation**: Weekly runs (vs. daily testing) → ~75-110 SEK/month\n",
    "- **Newsletter generation**: 4 reports/month → ~0.14 SEK/month (negligible)\n",
    "- **Chatbot queries**: \n",
    "  - 10 queries/day → ~2-3 SEK/month\n",
    "  - 50 queries/day → ~14 SEK/month\n",
    "  - 100 queries/day → ~28 SEK/month\n",
    "- **Expected steady-state**: 90-140 SEK/month (after development phase, with weekly pipeline + moderate chatbot usage)\n",
    "\n",
    "**ROI Assessment**:\n",
    "- Development phase cost: ~260 SEK/month (Oct 2025, includes testing and iterations)\n",
    "- Production phase estimate: ~90-140 SEK/month (automated weekly pipeline)\n",
    "- Cost reduction opportunity: Migrate chatbot to Azure AI Foundry for predictable pricing at scale\n",
    "- Budget discipline: Monitoring and alerts enabled, cost-conscious architecture demonstrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632182c",
   "metadata": {},
   "source": [
    "## 5. Discussion\n",
    "\n",
    "### 5.1 Design Decisions and Trade-offs\n",
    "\n",
    "**Cloud Service Tier Selection**:\n",
    "\n",
    "The project uses a mixed-tier approach balancing cost and functionality:\n",
    "\n",
    "**Azure AI Search - Free Tier (F)**:\n",
    "- **Decision**: Use free tier instead of paid (700-2300 SEK/month)\n",
    "- **Rationale**: 50MB capacity sufficient for thousands of articles, 10K document limit far exceeds current 588 articles\n",
    "- **Trade-off**: No semantic search (requires Standard S1 tier)\n",
    "- **Mitigation**: RAG chatbot with GPT-4.1-mini provides intelligent query understanding, achieving ~90% of semantic search benefits\n",
    "\n",
    "**Azure AI Language - Standard Tier (S)**:\n",
    "- **Decision**: Upgraded from Free tier after exceeding 5K transactions/month during testing\n",
    "- **Rationale**: Early deduplication and content filtering keep ongoing costs minimal despite higher limits\n",
    "- **Trade-off**: Pay-per-transaction pricing (~140-185 SEK/month during development)\n",
    "- **Justification**: Cost acceptable for production-quality NLP analysis, expected to decrease to ~75-110 SEK/month in steady-state\n",
    "\n",
    "**GitHub Models vs. Azure AI Foundry**:\n",
    "- **Decision**: Use GitHub Models (free) for development, migrate to Azure AI Foundry later\n",
    "- **Rationale**: Zero-cost prototyping with identical API, seamless migration (2-line code change)\n",
    "- **Trade-off**: Free tier rate limits (15-60 req/min), no SLA guarantees\n",
    "- **Migration triggers**: Hit rate limits, reach 50+ daily users, need production SLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72511885",
   "metadata": {},
   "source": [
    "### 5.2 Technical Challenges and Solutions\n",
    "\n",
    "**Challenge 1: Guardian API Fetching Historical Articles**\n",
    "\n",
    "**Problem**: Guardian API repeatedly fetched articles from December 2023 despite project focus on recent news (June 2025+).\n",
    "\n",
    "**Root Cause**: No date filtering at API level; all historical articles matching query returned.\n",
    "\n",
    "**Solution**: Added `from-date: '2025-06-01'` parameter to API request, filtering at source before expensive scraping and analysis.\n",
    "\n",
    "**Impact**: Eliminated wasted processing, reduced pipeline runtime, prevented stale data pollution.\n",
    "\n",
    "---\n",
    "\n",
    "**Challenge 2: Pipeline Inefficiency with Duplicate Articles**\n",
    "\n",
    "**Problem**: Pipeline scraped full article content BEFORE checking for duplicates, wasting ~2 minutes per run when no new articles existed.\n",
    "\n",
    "**Root Cause**: Deduplication occurred after scraping step in original pipeline design.\n",
    "\n",
    "**Solution**: Restructured pipeline to check URLs against registry immediately after fetching metadata, scraping only new articles.\n",
    "\n",
    "**Impact**: ~2 minutes saved per run, reduced HTTP requests, lower bandwidth usage.\n",
    "\n",
    "---\n",
    "\n",
    "**Challenge 3: Chatbot Temporal Query Failures**\n",
    "\n",
    "**Problem**: Query \"Summarize news from the last 24 hours\" incorrectly returned \"only 1 article\" when 29 were just added.\n",
    "\n",
    "**Root Cause**: No temporal query detection; semantic search matched keyword \"24 hours\" in old article content.\n",
    "\n",
    "**Solution**: Implemented regex-based temporal query detection with datetime cutoff calculation. Added `order_by=\"published_date desc\"` to Azure AI Search queries for efficient date-sorted retrieval.\n",
    "\n",
    "**Impact**: 100% accurate temporal filtering, comprehensive summaries of recent articles.\n",
    "\n",
    "---\n",
    "\n",
    "**Challenge 4: Token Limit Errors (413) in RAG Chatbot**\n",
    "\n",
    "**Problem**: Query \"What happened in 2023?\" with 15 articles exceeded GitHub Models 8000 token limit.\n",
    "\n",
    "**Root Cause**: Fixed 1500 chars/article truncation without considering total token budget or article count.\n",
    "\n",
    "**Solution**: Implemented adaptive token budget management:\n",
    "- Calculate available chars based on article count and metadata overhead\n",
    "- Default budget: 5000 tokens (single query), 3500 tokens (with history)\n",
    "- Dynamic per-article truncation: `chars_per_article = max(300, available_chars // num_articles)`\n",
    "\n",
    "**Impact**: Zero 413 errors in production, supports 15-20 articles per query.\n",
    "\n",
    "---\n",
    "\n",
    "**Challenge 5: Analytics Top Topics Dominated by Single-Source Boilerplate**\n",
    "\n",
    "**Problem**: Top 10 Topics showed entities with 146 mentions but from single article (conference speaker list spam).\n",
    "\n",
    "**Root Cause**: Entity frequency ≠ topic relevance; NER counted all mentions regardless of substantive coverage.\n",
    "\n",
    "**Solution**: Added cross-source filtering requiring minimum 2 sources per topic. Removed interactive sliders (one fixed value worked better). Added \"Articles\" and \"Sources\" columns for transparency.\n",
    "\n",
    "**Impact**: Clean list of genuine cross-source trends, eliminated boilerplate noise.\n",
    "\n",
    "---\n",
    "\n",
    "**Challenge 6: Responsive Design Issues on Mobile**\n",
    "\n",
    "**Problem**: Metrics cut off numbers, buttons split text into multiple lines, charts too small on narrow viewports.\n",
    "\n",
    "**Root Cause**: Fixed font sizes and column widths without viewport-based scaling or breakpoints.\n",
    "\n",
    "**Solution**: \n",
    "- Externalized CSS to separate file (350 lines)\n",
    "- Implemented viewport-based font scaling with `clamp()`\n",
    "- Added 4 breakpoint levels (1200px, 1024px, 768px, 480px)\n",
    "- Multi-layer overflow protection for metrics and buttons\n",
    "- Chart CSS scaling with responsive dimensions\n",
    "\n",
    "**Impact**: Professional appearance on all devices (desktop, laptop, tablet, mobile)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ec4de",
   "metadata": {},
   "source": [
    "### 5.3 Lessons Learned\n",
    "\n",
    "**Data Quality and Source Curation**\n",
    "\n",
    "The journey from 14 sources to 7 high-quality feeds taught a fundamental lesson about data curation: reliability beats volume. Removing problematic sources like EU-Startups (blocked by Azure's IP ranges), Dagens Industri (too much business, not enough AI), and Tom's Hardware (junk articles) wasn't a failure, it was a necessary refinement. The cross-source validation approach (requiring minimum 2 sources for trending topics) emerged as a solution to filter noise without manual intervention. This reflects a broader principle for enterprise systems: better to monitor fewer sources reliably than many sources with fragile scrapers that require constant maintenance.\n",
    "\n",
    "**Optimization and Cost Consciousness**\n",
    "\n",
    "Early optimizations proved their worth repeatedly throughout development. Moving URL deduplication before scraping saved 2 minutes per run, seemingly small, but compounding to hours over development cycles. Similarly, filtering articles under 100 characters before Azure AI analysis prevented wasted API calls that would have cost too much if continued. The compact JSON storage decision (removing indentation) reduced storage by 30-40% with a single line change. The cumulative impact on the monthly budget was significant: staying under 195 SEK through October despite the initial spike of Azure AI Language costs demonstrated that thoughtful engineering reduces operational costs.\n",
    "\n",
    "**RAG Architecture and Model Selection**\n",
    "\n",
    "Building the chatbot revealed nuanced insights about retrieval-augmented generation. Entity frequency doesn't equal semantic relevance: an entity mentioned 100 times in boilerplate conference lists provides less value than 5 mentions in substantive articles. Temporal query detection required explicit pattern matching rather than relying on semantic understanding alone. The decision to use GPT-4.1-mini over cheaper alternatives (like Phi-4-mini at 81% lower cost) was validated through actual usage: the quality difference (0.8066 vs 0.4429) justified the expense for user-facing features. The architecture demonstrated that combining free-tier keyword search with a quality language model achieves roughly 90% of semantic search capabilities at a fraction of the cost (0 SEK vs 700+ SEK monthly for Azure AI Search Standard tier).\n",
    "\n",
    "**AI-Assisted Development Reality**\n",
    "\n",
    "Working with Claude Sonnet 4.5 (via GitHub Copilot Chat) throughout this project provided quantifiable evidence of AI assistance value. The estimated **80% time savings** (completing in ~1 month what would have taken 5+ months traditionally) came from strategic use: letting AI generate boilerplate, API integrations, test utilities, and CSS implementations, while maintaining human oversight for architecture decisions, domain optimizations, and complex debugging. The workflow evolved: AI generates first draft → human reviews and refactors → iterate together → document why AI suggestions were modified. This isn't about replacing developer judgment; it's about accelerating implementation dramatically. With existing Azure and Streamlit knowledge, the acceleration came primarily from eliminating tedious documentation lookup, automating repetitive code patterns, and rapid iteration on UI/UX refinements. The 30+ utility scripts generated via AI assistance alone would have consumed several days of manual implementation.\n",
    "\n",
    "**Cost Management Reflections**\n",
    "\n",
    "The mixed free/paid tier strategy proved sustainable: Azure AI Search free tier still has 90% capacity available at 588 documents, while Azure AI Language Standard tier costs (140-185 SEK monthly during development) are expected to drop to 75-110 SEK in steady-state operation. Developing the chatbot on GitHub Models (free) before eventual Azure AI Foundry migration saved an estimated 470-940 SEK in prototyping costs. The 200 SEK budget alert threshold wasn't breached, validating the cost-conscious architectural decisions. This demonstrates that cloud services can be affordable for learning projects when tiers are chosen deliberately rather than defaulting to paid options.\n",
    "\n",
    "**Documentation as Development Tool**\n",
    "\n",
    "Maintaining session-by-session notes (38 documented sessions) and the GitHub Copilot instructions file transformed documentation from a chore into a development asset. These notes became the foundation for this comprehensive report, proving that writing down decisions as you make them is far easier than reconstructing them later. The collection of 30+ utility scripts (`test_*.py`, `debug_*.py`, `remove_*.py`) documents problem-solving approaches in executable form.\n",
    "\n",
    "**Personal Use Validates Design**\n",
    "\n",
    "Perhaps the most valuable lesson: building a tool you actually use creates a continuous feedback loop. Using the dashboard daily to check AI news revealed usability issues that wouldn't surface in abstract testing. The weekly newsletter landing in my own inbox forced honest evaluation of content quality and relevance. This personal stake in the product quality drove refinements that transformed a functional prototype into a genuinely useful system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a857994",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This project successfully validates a comprehensive architecture for enterprise-scale trend monitoring systems through a working AI news monitoring implementation. The system demonstrates that automated content collection, NLP analysis, knowledge base indexing, and intelligent user interaction can be implemented cost-effectively using cloud services and modern AI development tools.\n",
    "\n",
    "### 6.1 Technical Achievement\n",
    "\n",
    "The proof-of-concept delivers a complete, production-ready pipeline processing 588 indexed articles from 7 active sources with 99% deduplication efficiency. Integration with 5 Azure services (Blob Storage, AI Language, AI Search, Functions, Communication Services) operates at 90-140 SEK monthly in steady-state, well below the 200 SEK budget threshold. The architecture validates enterprise applicability across multiple domains: competitor intelligence, regulatory compliance tracking, market research, and brand management. Current free-tier Azure AI Search capacity (16% utilized at 588 documents) demonstrates clear scalability path supporting thousands of articles before requiring infrastructure upgrades.\n",
    "\n",
    "### 6.2 AI-Assisted Development Impact\n",
    "\n",
    "AI-assisted development using Claude Sonnet 4.5 (via GitHub Copilot Chat) proved transformative, achieving an estimated 80% reduction in development time (1 month actual vs. 5+ months traditional estimate). The time savings came primarily from automated boilerplate generation, rapid API integration, and elimination of extensive documentation lookup. This validates AI assistance as production-ready for complex cloud applications, with substantial ROI at enterprise scale: zero additional licensing cost beyond existing IDE subscriptions, while maintaining code quality through human oversight of architecture decisions and domain-specific optimizations.\n",
    "\n",
    "### 6.3 Enterprise Readiness and Future Path\n",
    "\n",
    "Current constraints - single-domain focus, English-only processing, manual source curation, keyword-only search, and personal-scale deployment - represent configuration choices rather than architectural limitations. The system's design supports straightforward extension to multi-tenant architecture, configuration-driven source management, semantic search (via paid Azure AI Search tier), and horizontal scaling. The transition from proof-of-concept to enterprise platform requires operational enhancements (monitoring, alerting, admin UI) rather than fundamental redesign, validating the architectural approach for production deployment.\n",
    "\n",
    "### 6.4 Final Reflection\n",
    "\n",
    "This project achieves its dual objectives: validating technical architecture for enterprise trend monitoring systems, and demonstrating AI-assisted development effectiveness for complex cloud applications. The combination of cost-conscious engineering (mixed free/paid Azure tiers), incremental implementation (6 phases), and strategic AI assistance produced a system that transitions seamlessly from student project to functional portfolio piece to enterprise proof-of-concept. The experience confirms that choosing personally relevant domains maintains motivation while creating practical value. The resulting tool serves daily as an AI news aggregator, proving its worth beyond academic requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd7a28",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "### 7.1 Technologies and Frameworks\n",
    "\n",
    "**Cloud Services**:\n",
    "- Microsoft Azure. (2025). *Azure Blob Storage Documentation*. https://learn.microsoft.com/en-us/azure/storage/blobs/\n",
    "- Microsoft Azure. (2025). *Azure AI Language Documentation*. https://learn.microsoft.com/en-us/azure/ai-services/language-service/\n",
    "- Microsoft Azure. (2025). *Azure AI Search Documentation*. https://learn.microsoft.com/en-us/azure/search/\n",
    "- Microsoft Azure. (2025). *Azure Functions Documentation*. https://learn.microsoft.com/en-us/azure/azure-functions/\n",
    "- Microsoft Azure. (2025). *Azure Communication Services Documentation*. https://learn.microsoft.com/en-us/azure/communication-services/\n",
    "\n",
    "**Python Libraries**:\n",
    "- Python Software Foundation. (2025). *Python 3.12 Documentation*. https://docs.python.org/3.12/\n",
    "- Streamlit Inc. (2025). *Streamlit Documentation*. https://docs.streamlit.io/\n",
    "- Beautiful Soup. (2025). *Beautiful Soup Documentation*. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- feedparser. (2025). *feedparser Documentation*. https://pythonhosted.org/feedparser/\n",
    "- Azure SDK for Python. (2025). *azure-storage-blob Documentation*. https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob\n",
    "- Azure SDK for Python. (2025). *azure-ai-textanalytics Documentation*. https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/textanalytics/azure-ai-textanalytics\n",
    "- Azure SDK for Python. (2025). *azure-search-documents Documentation*. https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents\n",
    "\n",
    "**AI Models and APIs**:\n",
    "- OpenAI. (2025). *GPT-4.1-mini Model Documentation*. https://platform.openai.com/docs/models\n",
    "- GitHub. (2025). *GitHub Models Documentation*. https://github.com/marketplace/models\n",
    "- The Guardian. (2025). *The Guardian Open Platform API Documentation*. https://open-platform.theguardian.com/documentation/\n",
    "\n",
    "### 7.2 Data Sources\n",
    "\n",
    "**News Publications**:\n",
    "- The Guardian. (2025). *AI Category*. https://www.theguardian.com/technology/artificialintelligenceai\n",
    "- TechCrunch. (2025). *AI News*. https://techcrunch.com/category/artificial-intelligence/\n",
    "- VentureBeat. (2025). *AI Coverage*. https://venturebeat.com/category/ai/\n",
    "- Ars Technica. (2025). *Artificial Intelligence Tag*. https://arstechnica.com/tag/artificial-intelligence/\n",
    "- Gizmodo. (2025). *AI Tag*. https://gizmodo.com/tag/ai\n",
    "- IEEE Spectrum. (2025). *Technology News*. https://spectrum.ieee.org/\n",
    "- The Register. (2025). *Tech News*. https://www.theregister.com/\n",
    "- The Verge. (2025). *AI Coverage*. https://www.theverge.com/ai-artificial-intelligence\n",
    "- EU-Startups. (2025). *European Startup News*. https://www.eu-startups.com/\n",
    "\n",
    "### 7.3 Tools and Development Environment\n",
    "\n",
    "**Development Tools**:\n",
    "- Microsoft. (2025). *Visual Studio Code*. https://code.visualstudio.com/\n",
    "- GitHub. (2025). *GitHub Copilot*. https://github.com/features/copilot\n",
    "- Anaconda. (2025). *Conda Documentation*. https://docs.conda.io/\n",
    "\n",
    "**Version Control**:\n",
    "- Git. (2025). *Git Documentation*. https://git-scm.com/doc\n",
    "- GitHub. (2025). *GitHub Documentation*. https://docs.github.com/\n",
    "\n",
    "**Project Management**:\n",
    "- GitHub. (2025). *GitHub Issues*. https://github.com/features/issues\n",
    "- Markdown Guide. (2025). *Markdown Reference*. https://www.markdownguide.org/\n",
    "\n",
    "---\n",
    "\n",
    "*This report was prepared as part of coursework at EC Utbildning in October 2025.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trend-monitor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
